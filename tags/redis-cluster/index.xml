<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kingjcy Blog</title>
    <link>http://kingjcy.github.io/tags/redis-cluster/index.xml</link>
    <description>Recent content on kingjcy Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2016. All rights reserved.</copyright>
    <atom:link href="http://kingjcy.github.io/tags/redis-cluster/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>redis cluster</title>
      <link>http://kingjcy.github.io/blog/2016/07/21/redis-cluster/</link>
      <pubDate>Thu, 21 Jul 2016 17:12:36 +0800</pubDate>
      
      <guid>http://kingjcy.github.io/blog/2016/07/21/redis-cluster/</guid>
      <description>&lt;p&gt;自从研究了redis的监控工具之后，对于redis的集群实现方案又回头做了一个系统的研究。
首先，先说一下redis，是一个高性能的key-value类型的NoSQL数据库，支持较为丰富的数据类型，
可以满足一般公司的需求，所以使用比较多，但是随着数据的越来越多，也迫切需求支持分布式集群。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;redis集群&#34;&gt;&lt;strong&gt;redis集群&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;目前redis集群已经有了较大的应用，包括官方也推出的redis3.0版本的集群部署方案。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;redis集群解决的问题&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;redis单线程特性，集群可以并发处理，更高效&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;单机内存有限&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;单点问题，缺乏高可用性&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;不能动态扩容&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;分片的实现&#34;&gt;分片的实现&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;范围分区：将固定范围的数据key放到对应的实例中。这个方案不是太好，需要维护映射关系。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;hash分区（一致性分区）：用哈希函数（例如crc32）将key转化为一个数字，然后取模来分配到不同的实例中。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;codis分区和redis3.0分区都是分了N个slot，先对key到slot进行hash分区再对slot进行范围分区或者hash分区。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;目前集群主要有四种部署方案&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;客户端分片&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;代理分片：twenproxy代理&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;codis&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;redis cluster&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;四种部署方案&#34;&gt;&lt;strong&gt;四种部署方案&lt;/strong&gt;&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;客户端分片&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;就是通过客户端来实现到不同的主机上的redis实例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kingjcy.github.io/image/redis-cluster-client.jpg&#34; alt=&#34;alt text&#34; title=&#34;Title&#34; /&gt;&lt;/p&gt;

&lt;p&gt;客户端分片是不用经过中间件，但是缺点太多了,所有的逻辑都在客户端，这样就导致了可运维性很差，首先，客户端存在着语言的差异，还有逻辑过分依赖于客户端，升级应用和扩展业务都依赖于客户端的开发，还存在着客户端版本和故障问题难以排查的问题。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;代理分片&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这边主要介绍的是曾被广泛使用的twenproxy作为中心代理的集群部署方案（twemproxy是twitter开源的一个redis和memcache代理服务器，只用于作为简单的代理中间件，目前twitter内部已经不再使用）。&lt;/p&gt;

&lt;p&gt;该集群主要是通过中间件twenproxy来实现，客户端只要通过中间件twenproxy提供的api和端口来进行操作，然后twenproxy提供路由能力（所有的key通过一致性哈希算法分布到集群中所有的redis实例中）到后台redis集群中的不同实例中，实现分布式集群。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kingjcy.github.io/image/redis-cluster-twenproxy.jpg&#34; alt=&#34;alt text&#34; title=&#34;Title&#34; /&gt;&lt;/p&gt;

&lt;p&gt;twenproxy还提供了一些其他保障集群稳定的功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;支持无效Redis实例的自动删除&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;代理与每个redis实例维持长连接，减少客户端和redis实例的连接数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;代理是无状态的，可以任意部署多套，避免单点问题&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认启用pipeline，连接复用，提高效率，性能损失在 10% - 20%&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这套部署方案，采用组件分离，升级容易，但是这个部署方案有一个很大的缺陷：无法动态扩容，不能平缓的增减redis实例，而且中间件也会消耗性能，在并发上，要求代理数量和实例一致甚至更多才能更好的发挥并发能力。造成运维工作量很大。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;codis&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;codis是豌豆荚开源一款分布式集群的方案，它是在redis2.8.21的基础上使用go和c改出来的，其实也是类似于twenproxy的代理模式，但是它可以实现平滑的新增实例，也就是动态扩容。&lt;/p&gt;

&lt;p&gt;Codis中采用预分片的形式，启动的时候就创建了1024个slot，1个slot相当于1个箱子，每个箱子有固定的编号，范围是1~1024。slot这个箱子用作存放Key，至于Key存放到哪个箱子，可以通过算法“crc32(key)%1024”获得一个数字，这个数字的范围一定是1~1024之间，Key就放到这个数字对应的slot。例如，如果某个Key通过算法“crc32(key)%1024”得到的数字是5，就放到编码为5的slot（箱子）。1个slot只能放1个Redis Server Group，不能把1个slot放到多个Redis Server Group中。1个Redis Server Group最少可以存放1个slot，最大可以存放1024个slot。因此，Codis中最多可以指定1024个Redis Server Group。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kingjcy.github.io/image/redis-cluster-codis.jpg&#34; alt=&#34;alt text&#34; title=&#34;Title&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这边对codis四大组成部分&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议, 表现得和一个原生的 Redis 没什么区别 (就像 Twemproxy), 对于一个业务来说, 可以用Keepalived等负载均衡软件部署多个 codis-proxy实现高可用, codis-proxy 本身是无状态的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard, 用户可以直接在浏览器上观察 Codis 集群的运行状态，可以完善运维。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.21 开发, 加入了 slot 的支持和原子的数据迁移指令. Codis 上层的 codis-proxy 和 codis-config 只能和这个版本的 Redis 交互才能正常运行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ZooKeeper：Codis依赖于ZooKeeper存储数据路由表的信息和Codis Proxy节点的元信息。另外，Codisconfig发起的命令都会通过ZooKeeper同步到CodisProxy的节点。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;依然有中间件的性能消耗问题，但是解决了动态扩容问题。这个思路是目前大多数公司在用的。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;redis3.0&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;redis3.0集群部署方案是官方在发布redis3.0版本的时候提供的，它采用了p2p模式，完全去中心化。依然采用预分片的模式，Redis把所有的Key分成了16384个slot，每个Redis实例负责其中一部分slot。slot 和 server 的映射关系存储每一个 server 的路由表中，集群中的所有信息（节点、端口、slot等），都通过节点之间定期的数据交换而更新。Redis客户端在任意一个Redis实例发出请求，如果所需数据不在该实例中，通过重定向命令引导客户端访问所需的实例。在存储时，根据 CRC16(key) mod 16384 的值，决定将一个key放到哪一个slot中。当数据迁移时就是调整 slot 的分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kingjcy.github.io/image/redis-cluster-3.0.jpg&#34; alt=&#34;alt text&#34; title=&#34;Title&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;无中心化结构，每个节点都保存数据和整个集群的状态。&lt;/li&gt;
&lt;li&gt;采用 gossip 协议传播信息以及发现新节点（最终一致性）。gossip协议要求每个节点和其他节点保持连接，会利用PING/PONG来发送节点相关的数据，更新节点的路由表，如果设置的时间较短或者节点较多的话，还是比较客观的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而且目前官方只提供了一个ruby程序 redis-trib 完成集群的所有操作，缺乏监控管理工具，很难清楚目前集群的状态。目前并没有得到大规模的使用。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>