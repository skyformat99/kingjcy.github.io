<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kingjcy Blog</title>
    <link>http://kingjcy.github.io/tags/shell/index.xml</link>
    <description>Recent content on kingjcy Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2016. All rights reserved.</copyright>
    <atom:link href="http://kingjcy.github.io/tags/shell/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>shell 积累</title>
      <link>http://kingjcy.github.io/blog/2016/03/02/shell-%E7%A7%AF%E7%B4%AF/</link>
      <pubDate>Wed, 02 Mar 2016 17:26:28 +0800</pubDate>
      
      <guid>http://kingjcy.github.io/blog/2016/03/02/shell-%E7%A7%AF%E7%B4%AF/</guid>
      <description>&lt;p&gt;shell主要是用于linux的系统操作的脚本语言，python主要适用于web界面的，如果用python写一些linux系统的东西会比较冗余。&lt;/p&gt;

&lt;p&gt;shell是一个命令解释器，也就是我们常说的bash(bash只是shell中最常用的一种，还有很多shell解释器)，是与操作系统直接进行交互的还可以支持多种编程化操作的强大工具。&lt;/p&gt;

&lt;p&gt;shell是一种很强大的脚本语言，也是操作终端的利器，用好shell可以让你在linux环境开发中如鱼得水，这边别学习别记录，便于备忘与查找。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;场景&#34;&gt;场景&lt;/h2&gt;

&lt;p&gt;不适合shell的场景&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;密集型任务，需要计算，hash，排序&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对跨平台和安全性有要求的&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;大量文件操作，图型操作，io和socket&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这些不适用的场景可以用强大一点的脚本语言python，ruby，perl，或者高层次的编译语言c/c++，java等。&lt;/p&gt;

&lt;p&gt;##shell基本语法&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;开头
#!/bin/sh&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;符号#!用来告诉系统它后面的参数是用来执行该文件的程序,是一个解释器的标记。在这个例子中我们使用/bin/sh来执行程序。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 #!/bin/sh
2 #!/bin/bash
3 #!/usr/bin/perl 
4 #!/usr/bin/tcl 
5 #!/bin/sed -f
6 #!/usr/awk -f
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;特殊字符&lt;/p&gt;

&lt;h1 id=&#34;注释&#34;&gt;注释&lt;/h1&gt;

&lt;p&gt;/ 转义
; 命令分隔符
;; case终止符&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case &amp;quot;$variable&amp;quot; in
abc) echo &amp;quot;\$variable = abc&amp;quot; ;; 
xyz) echo &amp;quot;\$variable = xyz&amp;quot; ;; 
esac
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;. source/正则中匹配任意字符
, 逗号链接了一系列的算术操作,虽然里边所有的内容都被运行了,但只有最后一项被 返回
` 后置引用,命令替换&lt;/p&gt;

&lt;dl&gt;
&lt;dd&gt;&lt;p&gt;空命令
$ 变量替换,在正则表达式中作为行结束符
${} 参数替换
() 命令组.如:(a=hello;echo)  在()中的命令列表,将作为一个子 shell 来运行. 在()中的变量,由于是在子 shell 中,所以对于脚本剩下的部分是不可用的. 如:&lt;/p&gt;

&lt;p&gt;a=123
( a=321; )&lt;/p&gt;

&lt;p&gt;echo&amp;rdquo;a=$a&amp;rdquo;&lt;/p&gt;

&lt;p&gt;a=123&lt;/p&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;{} 这个结构创建了一个匿名的函数.但是与函数不同的是,在其中声明的变量,对于脚本其他部分的代码来说还是可见的,在大括号中,不允许有空白,除非这个空白是有意义的
    a=123
    ( a=321; )&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo&amp;quot;a=$a&amp;quot; 

a=321
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;amp;&amp;gt;&amp;gt;&amp;amp;&amp;gt;&amp;gt;&amp;lt; 重定向.
scriptname &amp;gt;filename 重定向脚本的输出到文件中.覆盖文件原有内容.
command &amp;amp;&amp;gt;filename 重定向 stdout 和 stderr 到文件中
command &amp;gt;&amp;amp;2 重定向 command 的 stdout 到 stderr
scriptname &amp;gt;&amp;gt;filename 重定向脚本的输出到文件中.添加到文件尾端,如果没有文件, 则创建这个文件.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;| 管道
子进程的运行的管道,不能够改变脚本的变量.
1 variable=&amp;ldquo;initial_value&amp;rdquo;
2 echo &amp;ldquo;new_value&amp;rdquo; | read variable
3 echo &amp;ldquo;variable = $variable&amp;rdquo; #variable = initial_value&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;| 强制重定向&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;|| 或-逻辑操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 if [ $condition1 ] || [ $condition2 ]
2 if [ $condition1 -o $condition2 ] 相同
3 # 如果 condition1 或 condition2 为 true,那结果就为 true.
4
5 if [[ $condition1 || $condition2 ]] # 也可以
6 # 注意||不允许出现在[ ... ]中.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;amp;&amp;amp; 与-逻辑操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 if [ $condition1 ] &amp;amp;&amp;amp; [ $condition2 ]
2 与if [ $condition1 -a $condition2 ] 相同
3 # 如果 condition1 和 condition2 都为 true,那结果就为 true.
4
5 if [[ $condition1 &amp;amp;&amp;amp; $condition2 ]] # 也可以.
6 # 注意&amp;amp;&amp;amp;不允许出现在[ ... ]中.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;- 选项,前缀.在所有的命令内如果想使用选项参数的话,前边都要加上&amp;rdquo;-&amp;ldquo;,之前工作的目录&lt;/p&gt;

&lt;p&gt;^ 行首,正则表达式中表示行首.&amp;ldquo;^&amp;ldquo;定位到行首.&lt;/p&gt;

&lt;p&gt;exit 退出脚本&lt;/p&gt;

&lt;p&gt;((&amp;hellip;))与 let 命令很像,允许算术扩展和赋值.举个简单的例子 a=$(( 5 + 3 )),将把 a 设为 &amp;ldquo;5+3&amp;rdquo;或者 8.然而,双圆括号也是一种在 Bash 中允许使用 C 风格的变量处理的机制.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;变量&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在shell编程中，所有的变量都由字符串组成，并且您不需要对变量进行声明，直接赋值就可以，应用变量的话，用$+变量名的形式。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;等号前后不能有空格,如果赋值后面是执行语句，需要用&lt;code&gt;来表示，执行语句都是用&lt;/code&gt;都可以不一定语句后&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数组&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A=(1 1 2 3)  定义
${A[i]}    取数组的值,重0开始的
${A[@]}     显示所有的参数
${#A[@]}    显示参数的个数
${A[@]/1/2}  将一换成2
unset A[2]  删除A[2]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function command()
{

}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;重定向：将命令的结果输出到文件，而不是标准输出（屏幕）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;写入文件并覆盖旧文件
&amp;gt; 加到文件的尾部，保留旧文件内容。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;流程控制&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;判断&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if .... then 
.... 
elif .... then 
.... 
else 
.... 
fi

当 if 和 then 在一个条件测试的同一行中的话,必须使用&amp;quot;;&amp;quot;


通常用&amp;quot; [ ] &amp;quot;来表示条件测试。注意这里的空格很重要。要确保方括号的空格。 
[ -f &amp;quot;somefile&amp;quot; ] ：判断是否是一个文件 
[ -x &amp;quot;/bin/ls&amp;quot; ] ：判断/bin/ls是否存在并有可执行权限 
[ -n &amp;quot;$var&amp;quot; ] ：判断$var变量是否有值 
[ &amp;quot;$a&amp;quot; = &amp;quot;$b&amp;quot; ] ：判断$a和$b是否相等 ,注意“=”和变量之间要有空格。
多重条件可以用&amp;amp;&amp;amp;或者||来逻辑判断，但是用两个[]来使用，例如[]||[]

1.整数比较 
-eq 等于,如:if [ &amp;quot;$a&amp;quot; -eq &amp;quot;$b&amp;quot; ]   
-ne/!= 不等于,如:if [ &amp;quot;$a&amp;quot; -ne &amp;quot;$b&amp;quot; ] 
-gt 大于,如:if [ &amp;quot;$a&amp;quot; -gt &amp;quot;$b&amp;quot; ]   
-ge 大于等于,如:if [ &amp;quot;$a&amp;quot; -ge &amp;quot;$b&amp;quot; ]   
-lt 小于,如:if [ &amp;quot;$a&amp;quot; -lt &amp;quot;$b&amp;quot; ]   
-le 小于等于,如:if [ &amp;quot;$a&amp;quot; -le &amp;quot;$b&amp;quot; ]   
&amp;lt;   小于(需要双括号),如:((&amp;quot;$a&amp;quot; &amp;lt; &amp;quot;$b&amp;quot;))   
&amp;lt;=  小于等于(需要双括号),如:((&amp;quot;$a&amp;quot; &amp;lt;= &amp;quot;$b&amp;quot;))   
&amp;gt;   大于(需要双括号),如:((&amp;quot;$a&amp;quot; &amp;gt; &amp;quot;$b&amp;quot;))   
&amp;gt;   &amp;gt;=  大于等于(需要双括号),如:((&amp;quot;$a&amp;quot; &amp;gt;= &amp;quot;$b&amp;quot;))   



2.字符串比较

= 等于,如:if [ &amp;quot;$a&amp;quot; = &amp;quot;$b&amp;quot; ]   
== 等于,如:if [ &amp;quot;$a&amp;quot; == &amp;quot;$b&amp;quot; ],与=等价  




[[ $a == z* ]]   # 如果$a以&amp;quot;z&amp;quot;开头(模式匹配)那么将为true   
[[ $a == &amp;quot;z*&amp;quot; ]] # 如果$a等于z*(字符匹配),那么结果为true   

  [ $a == z* ]     # File globbing 和word splitting将会发生   
  [ &amp;quot;$a&amp;quot; == &amp;quot;z*&amp;quot; ] # 如果$a等于z*(字符匹配),那么结果为true



还有一些参数的比较见下面一个专题
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;循环&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while
while表达式： ----------while read line    这边的line只是一个变量，read应该读到换行符就解释
while ...; do 
.... 
done &amp;lt; filename   -----追加文件输入

可以用关键字&amp;quot;break&amp;quot; 用来跳出循环；也可以用关键字”continue”用来不执行余下的部分而直接跳到下一个循环。大部分和for差不多，但是有一些必须使用while，比如无限循环。一般和read一起使用对文件进行操作，比如行操作，read line大部分和for差不多，但是有一些必须使用while，比如无限循环。一般和read一起使用，read读取数据。，read读取数据。

for var in ....; do 
.... 
done 

在一个 for 循环中忽略[list]的话,将会使循环操作$@(从命令行传递给脚本的参数

也可以使用命令替换来产生 for 循环的[list],例如`seq 1 15`

for在shell中十分强大，它在批量操作，批量部署上有这个很大的优势。

until 条件
do
done

直到条件满足才退出
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;选择&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case &amp;quot;$variable&amp;quot; in
&amp;quot;$condition1&amp;quot;) command...
;;
&amp;quot;$condition1&amp;quot;) command...
;;
esac
注意: 对变量使用&amp;quot;&amp;quot;并不是强制的,因为不会发生单词分离. 每句测试行,都以右小括号)结尾.
每个条件块都以两个分号结尾;;.
case 块的结束以 esac(case 的反向拼


select i in var
do
done

一般与变量PS3结合使用

PS3=&amp;quot;what do you like:&amp;quot;
selct i in centos ubuntu readhat
do 
    echo &amp;quot;you like $i&amp;quot;
done

1)centos
2)ubuntu
3)readhat
what do you like:1
you like centos

可以结合上面的case进行步骤操作。
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;awk&#34;&gt;awk&lt;/h2&gt;

&lt;p&gt;awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;使用方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;awk &amp;lsquo;{pattern + action}&amp;rsquo; {filenames}
尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。&lt;/p&gt;

&lt;p&gt;awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。&lt;/p&gt;

&lt;p&gt;通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;实例&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@www ~]# last -n 5 &amp;lt;==仅取出前五行
root     pts/1   192.168.1.100  Tue Feb 10 11:21   still logged in
root     pts/1   192.168.1.100  Tue Feb 10 00:46 - 02:28  (01:41)
root     pts/1   192.168.1.100  Mon Feb  9 11:41 - 18:30  (06:48)
dmtsai   pts/1   192.168.1.100  Mon Feb  9 11:41 - 11:41  (00:00)
root     tty1                   Fri Sep  5 14:09 - 14:10  (00:01)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果只是显示最近登录的5个帐号&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#last -n 5 | awk  &#39;{print $1}&#39;
root
root
root
dmtsai
root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;awk工作流程是这样的：读入有&amp;rsquo;\n&amp;rsquo;换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是&amp;rdquo;空白键&amp;rdquo; 或 &amp;ldquo;[tab]键&amp;rdquo;,所以$1表示登录用户，$3表示登录用户ip,以此类推。&lt;/p&gt;

&lt;p&gt;NF最后一行，NR是最后一列。&lt;/p&gt;

&lt;p&gt;指定分隔符 awk -F: &amp;lsquo;{print &amp;ldquo;01: &amp;ldquo;$1}&amp;lsquo;,这个就以：分域了。可以在print中添加注解，相当于拼接字符串。&lt;/p&gt;

&lt;p&gt;简单用法，有时间继续补充&lt;/p&gt;

&lt;h2 id=&#34;空格&#34;&gt;空格&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;等号赋值两边不能有空格, var=string command,针对=后面跟上命令的，可以有空格，但是后面的命令必须要用``来执行，注意&lt;/li&gt;
&lt;li&gt;命令与选项之间需要空格&lt;/li&gt;
&lt;li&gt;管道两边空格可有可无&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;sed&#34;&gt;sed&lt;/h2&gt;

&lt;p&gt;sed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法&lt;/p&gt;

&lt;p&gt;sed命令行格式为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed [-nefri] ‘command’ 输入文本

常用选项：
    -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。
    -e∶直接在指令列模式上进行 sed 的动作编辑；
    -f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作；
    -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法)
    -i∶直接修改读取的档案内容，而不是由萤幕输出。 不加则不修改源文件      

常用命令：
     a   ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～
     c   ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！
     d   ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚；
     i   ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；
     p  ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～
     s  ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！

主要用于查找替换

sed &amp;quot;s/a/b/g&amp;quot; filename      替换，b替换a
sed &amp;quot;s/^/&amp;amp; /g&amp;quot; filename     开头是^,结尾是$,添加&amp;amp;，这些都是正则里面的，可以用于其他的比如grep，学会举一反三
sed &amp;quot;/a/a b/&amp;quot; filename      查找追加，追加a，在前面加i
sed &amp;quot;1p&amp;quot;                    打印第一行，一到五行1，5p，匹配打印这一行/a/p,最后一行$p

例如：

1. 在文件最后追加一些内容，常用于配置

sed -i &amp;quot;$a 内容&amp;quot; filename 可以用于追加内容，但是觉得还是直接用echo &amp;quot;&amp;quot; &amp;gt;&amp;gt; filename好一点

2.还可以在每个行首行尾追加内容

sed -i &amp;quot;s/$/&amp;amp; 内容/g&amp;quot; filename
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;变量&#34;&gt;$变量&lt;/h2&gt;

&lt;p&gt;特殊变量列表&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;变量     含义
$0     当前脚本的文件名
$n     传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。
$#     传递给脚本或函数的参数个数。
$*     传递给脚本或函数的所有参数。
$@     传递给脚本或函数的所有参数。被双引号(&amp;quot; &amp;quot;)包含时，与 $* 稍有不同，下面将会讲到。
$?     上个命令的退出状态，或函数的返回值。0表示成功，可以用于脚本的命令执行状态的判断。
$$     当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开头
    #!/bin/sh&lt;/p&gt;

&lt;h3 id=&#34;多台服务器&#34;&gt;多台服务器&lt;/h3&gt;

&lt;p&gt;ue是很好的文本编辑器，用于处理文本编辑上具有很大的优势，包括块处理，替换，编码上，要学会用它来编辑我们需要的文档，比如今天的ip端口的整理替换用于shell脚本来跑&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装redis&lt;/p&gt;

&lt;p&gt;redis=(10.147.0.1 10.147.0.107 10.147.0.16 10.147.0.31 10.147.0.17 10.147.0.32 10.147.0.46 10.147.0.61 10.147.0.47 10.147.0.62 10.147.0.76 10.147.0.91 10.147.0.77 10.147.0.92)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这边给变量赋值，这些ip在ue中可以很好的处理。等于号前后不能有空格，数组就是用大括号和逗号来表达&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for x in ${redis[@]}
do
ssh $x -t &amp;quot;mkdir -p /root/redis&amp;quot;
done

for x in ${redis[@]};do scp redis-3.2.8.tar.gz root@$x:/root/redis; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边把安装包重一台机器上复制到所有的机器上。-t 该参数通过指定一个伪终端迫使SecureShell客户端以交互模式工作，即使在给定命令的情况下也是如此。它被用于执行在远地主机上的基于屏幕的程序。通过-t参数来执行后面的命令，然后退出。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for x in ${redis[@]}
do 
ssh $$x -t &amp;quot;tar -zxf redis-3.2.8.tar.gz &amp;amp;&amp;amp; cd redis-3.2.8 &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make PREFIX=/usr/lib/redis install &amp;amp;&amp;amp; chown -R  hnapp:hnapp /usr/lib/redis &amp;amp;&amp;amp; chmod 777 -R /usr/lib/redis&amp;quot;&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这边就是把所有的机器上安装上redis,可以将所有的命令进行联合用&amp;amp;&amp;amp;。这样用shell的for循环在一台机器上处理所有机器的安装，可以大幅度提高工作效率和减少出错。&lt;/p&gt;

&lt;p&gt;修改所有机器的密码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for x in ${cxx[@]}; do ssh $x -t &amp;quot;echo Rljgvz0j | passwd --stdin root&amp;quot;; done
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;创建集群的配置文件&lt;/p&gt;

&lt;p&gt;for x in ${redis[@]}; do ssh $x -t &amp;ldquo;mkdir /usr/lib/redis/conf&amp;rdquo;; done
cd /usr/lib/redis/conf
vi redis-common.conf
for x in ${redis[@]}; do scp redis-common.conf $x:&lt;code&gt;pwd&lt;/code&gt;; done&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可以这样创建一个公共配置文件include在每个配置文件中,这边有一个pwd指令是指当前目录，上面这个是正常的方法，下面我们来使用单个配置文件&lt;/p&gt;

&lt;p&gt;首先在一台机器上创建一个配置文件redis-.conf，在文件文件中需要改变的设置为变量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;daemonize yes
tcp-backlog 511
timeout 0
tcp-keepalive 0
loglevel notice
databases 16
dir xccccccccccccccccccc
slave-serve-stale-data yes
slave-read-only yes
repl-disable-tcp-nodelay yes
slave-priority 100
appendonly yes
appendfsync everysec
no-appendfsync-on-rewrite yes
auto-aof-rewrite-min-size 64mb
lua-time-limit 5000
cluster-enabled yes
cluster-node-timeout 15000
cluster-migration-barrier 1
slowlog-log-slower-than 10000
slowlog-max-len 128
notify-keyspace-events &amp;quot;&amp;quot;
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-entries 512
list-max-ziplist-value 64
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
aof-rewrite-incremental-fsync yes
port 6379
maxmemory cxxxxxxxxxxxxx
maxmemory-policy allkeys-lru
appendfilename &amp;quot;appendonly-6379.aof&amp;quot;
dbfilename dump-6379.rdb
cluster-config-file nodes-6379.conf
auto-aof-rewrite-percentage 80-100
logfile xcxcxcxcxcxcxcxcxcxc
protected-mode no
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后写脚本redis_install.sh来替换变量，生成对应的配置文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash                                                     ----shell脚本的可执行文件，类似的python都是这样声明

clusterName=$1                                                  ----获取shell的参数$1-n
memCache=$2 

----因为嵌套在下面的循环中，会导致冲突，所有这边单独拿出来跑一边
rm -f mkredisdir.sh
echo &amp;quot;#!/bin/bash&amp;quot; &amp;gt;&amp;gt; mkredisdir.sh
cat redis_$clusterName.txt | awk -F&#39;[: ]&#39; &#39;{for(i=2;i&amp;lt;=NF;i++){printf(&amp;quot;ssh %s -ttt \&amp;quot;mkdir -p /data1/redis/%s\&amp;quot; \n&amp;quot;,$1,$i)}}&#39; &amp;gt;&amp;gt; mkredisdir.sh  ----NF最后一行，NR是最后一列。
chmod 755 mkredisdir.sh
./mkredisdir.sh
if [ $? -ne 0 ];then
    exit 1
fi




while read line                                                 ----while循环结构do,done,读一行read line
do
    IP=`echo ${line} |  awk -F: &#39;{print $1}&#39;`                   ----获取文件中一行的ip,awk对line进行域划分，这边获取第一域            
    dirName=`echo /usr/lib/redis/conf/$clusterName/`            ----获取文件名，这个shell中用``来执行命令，获取对结果给变量
    portList=(`echo ${line} |  awk -F: &#39;{print $2}&#39; | tr -d &#39;|&#39;`)   ----这边获取端口list,用tr删除所有的|
    for x in ${portList[@]}                                         ----在端口中循环
    do

        logfile=&amp;quot;/data1/redis/$x/$x.log&amp;quot;                            ----获取日志文件名
        tmpFileName=/tmp/redis-$x.conf                              ----临时文件名,tmp目录下系统是自动清理的，一般清理十天前的文件
        sed &amp;quot;s/6379/$x/g&amp;quot; redis-.conf &amp;gt; $tmpFileName                ----把redis-.conf文件中的6379替换为变量$x重写到新文件中
        sed -i &amp;quot;s#xccccccccccccccccccc#/data1/redis/$x#g&amp;quot; $tmpFileName  ----这边是把新文件中的xccccccccccccccccccc替换为/data1/redis/$x，如果变量中含有／就用#
        sed -i &amp;quot;s/cxxxxxxxxxxxxx/$memCache/g&amp;quot; $tmpFileName
        sed -i &amp;quot;s#xcxcxcxcxcxcxcxcxcxc#$logfile#g&amp;quot; $tmpFileName
        scp $tmpFileName $IP:${dirName}/                                ----将对应的配置文件拷贝到对应主机的目录下
        if [ $? -ne 0 ];then                                            ----如果失败则退出
            echo &amp;quot;scp  $tmpFileName to $IP failed.&amp;quot;
            exit 1
        fi
    done
done &amp;lt; redis_${clusterName}.txt                                         ----输入文件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;写脚本的时候可以使用-X来调试shell脚本，&amp;rdquo;-x&amp;rdquo;选项可用来跟踪脚本的执行，是调试shell脚本的强有力工具。“-x”选项使shell在执行脚本的过程中把它实际执行的每一个命令行显示出来，并且在行首显示一个&amp;rdquo;+&amp;ldquo;号。 &amp;ldquo;+&amp;ldquo;号后面显示的是经过了变量替换之后的命令行的内容，有助于分析实际执行的是什么命令。 “-x”选项使用起来简单方便，可以轻松对付大多数的shell调试任务,应把其当作首选的调试手段。
这边需要看一下解析的文件才能看懂&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10.147.0.1:6000 6001
10.147.0.107:6020 6021
10.147.0.16:6040 6041
10.147.0.31:6060 6061
10.147.0.17:6080 6081
10.147.0.32:6100 6101
10.147.0.46:6120 6121
10.147.0.61:6140 6141
10.147.0.47:6160 6161
10.147.0.62:6180 6181
10.147.0.76:6200 6201
10.147.0.91:6220 6221
10.147.0.77:6240 6241
10.147.0.92:6260 6261
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就可以生成所有redis需要的配置文件并且在对应的主机路径,下面就是启动所有的redis&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for x in ${redis[@]}; do ssh $x; done  -------这样可以按循序一台台主机上进行操作，然后没有把握的大批量数据就这样操作，如果又把我可以直接ssh $x -t ``
find /usr/lib/redis/conf/ -name &amp;quot;*.conf&amp;quot; |  xargs -i /usr/lib/redis/bin/redis-server {}  ----获取的序列可以直接给{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动好后就要给redis配备集群角色了，先安装ruby，gem,以及redis的gem包&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for x in ${redis[@]}; do  ssh $x -t &amp;quot;yum install -y ruby;gem install -l redis-3.2.2.gem&amp;quot;; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后生成tb脚本&lt;/p&gt;

&lt;p&gt;首先上面的文件处理成ip:port&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;awk &#39;{

for(i=2;i&amp;lt;=NF;i++){
    if (i!=NF){
        printf(&amp;quot;%s:%s &amp;quot;,$1,$i)
    }else{
        printf(&amp;quot;%s:%s \n&amp;quot;,$1,$i)}
}

}&#39; REDIS_W_DICT_NAT.txt &amp;gt; REDIS_W_DICT_NAT_cluster.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后生成shell脚本createsh.sh来生成对应的ruby脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash

fileName=$1                                                                         ----正常获取启动参数
masterList=`awk &#39;{for(i=1;i&amp;lt;=NF;i++){                                               ----按行循环，如果这一列是奇数则取奇数位，偶数则取偶数位，最终获取所有的主的ip和port
    if(NR%2!=0){
        if(i%2!=0){
            printf(&amp;quot;\&amp;quot;%s\&amp;quot;,&amp;quot;,$i)
        }
    }else{
        if(i%2==0){
            printf(&amp;quot;\&amp;quot;%s\&amp;quot;,&amp;quot;,$i)
        }
    }
    }
}&#39; $fileName`


masterListForStr=`echo $masterList | tr -s &#39;,&#39; &#39; &#39; | tr -d &#39;&amp;quot;&#39;`                     ----将重复的空格和逗号都删除，并删除引号
masterList=`echo [${masterList%,}]`                                                     


num=1
master=&amp;quot;&amp;quot;
slave=&amp;quot;&amp;quot;
cxx1=(`sed -n &#39;1&#39;p $fileName`)                                                      ----p是打印对应的行，这个就是获取第一行
cxx2=(`sed -n &#39;2&#39;p $fileName`)
cxx3=(`sed -n &#39;3&#39;p $fileName`)
cxx4=(`sed -n &#39;4&#39;p $fileName`)
cxx5=(`sed -n &#39;5&#39;p $fileName`)
cxx6=(`sed -n &#39;6&#39;p $fileName`)
cxx7=(`sed -n &#39;7&#39;p $fileName`)
cxx8=(`sed -n &#39;8&#39;p $fileName`)
cxx9=(`sed -n &#39;9&#39;p $fileName`)
cxx10=(`sed -n &#39;10&#39;p $fileName`)
cxx11=(`sed -n &#39;11&#39;p $fileName`)
cxx12=(`sed -n &#39;12&#39;p $fileName`)
cxx13=(`sed -n &#39;13&#39;p $fileName`)
cxx14=(`sed -n &#39;14&#39;p $fileName`)

lineCount=`awk &#39;END{print NF}&#39; $fileName`                                           ----end是指处理完所有的执行，这边就是获取一行有多少个数据

num=0
num2=1
while [ $num -lt $lineCount ]
do
    eval str1=&#39;$&#39;{cxx1[${num}]}                                                     ----存在变量的变量需要用eval，获取第一列的所有数据
    eval str2=&#39;$&#39;{cxx2[${num}]}
    eval str3=&#39;$&#39;{cxx3[${num}]}
    eval str4=&#39;$&#39;{cxx4[${num}]}
    eval str5=&#39;$&#39;{cxx5[${num}]}
    eval str6=&#39;$&#39;{cxx6[${num}]}
    eval str7=&#39;$&#39;{cxx7[${num}]}
    eval str8=&#39;$&#39;{cxx8[${num}]}
    eval str9=&#39;$&#39;{cxx9[${num}]}
    eval str10=&#39;$&#39;{cxx10[${num}]}
    eval str11=&#39;$&#39;{cxx11[${num}]}
    eval str12=&#39;$&#39;{cxx12[${num}]}
    eval str13=&#39;$&#39;{cxx13[${num}]}
    eval str14=&#39;$&#39;{cxx14[${num}]}

    res=`expr $num2 % 2`                                                            ----执行算数用expr
    if [ &amp;quot;X$res&amp;quot; = &amp;quot;X1&amp;quot; ];then                                                      ----奇数重上往下，偶数重下往上，生成上下key/value结构，json格式
        str=&amp;quot;$str,\&amp;quot;${str1}\&amp;quot;:\&amp;quot;${str2}\&amp;quot;,\&amp;quot;${str3}\&amp;quot;:\&amp;quot;${str4}\&amp;quot;,\&amp;quot;${str5}\&amp;quot;:\&amp;quot;${str6}\&amp;quot;,\&amp;quot;${str7}\&amp;quot;:\&amp;quot;${str8}\&amp;quot;,\&amp;quot;${str9}\&amp;quot;:\&amp;quot;${str10}\&amp;quot;,\&amp;quot;${str11}\&amp;quot;:\&amp;quot;${str12}\&amp;quot;,\&amp;quot;${str13}\&amp;quot;:\&amp;quot;${str14}\&amp;quot;&amp;quot;
    else
        str=&amp;quot;$str,\&amp;quot;${str14}\&amp;quot;:\&amp;quot;${str13}\&amp;quot;,\&amp;quot;${str12}\&amp;quot;:\&amp;quot;${str11}\&amp;quot;,\&amp;quot;${str10}\&amp;quot;:\&amp;quot;${str9}\&amp;quot;,\&amp;quot;${str8}\&amp;quot;:\&amp;quot;${str7}\&amp;quot;,\&amp;quot;${str6}\&amp;quot;:\&amp;quot;${str5}\&amp;quot;,\&amp;quot;${str4}\&amp;quot;:\&amp;quot;${str3}\&amp;quot;,\&amp;quot;${str2}\&amp;quot;:\&amp;quot;${str1}\&amp;quot;&amp;quot;
    fi  

    ((num = num + 1))
    ((num2 = num2 + 1))
done

#echo $master
str=`echo $str | cut -c 2-`                                                         ----删除第一个逗号
str=`echo &amp;quot;{$str}&amp;quot;`

slaveListForStr=`/usr/bin/python &amp;lt;&amp;lt;EOF                                              ----开始结束,将python嵌入到shel中，输出字符直接给一个变量

allDict=$str                                                                        ----将json格式到字符串给python中到数组，类似于c++中到vector
masterList=$masterList
slaveStr=&amp;quot;&amp;quot;
for master in masterList:
    slaveStr=slaveStr + &amp;quot; &amp;quot; + allDict[master]                                       ----进行匹配
    print slaveStr


EOF`
echo &amp;quot;/root/redis-3.2.8/src/redis-trib.rb create --replicas 1 &amp;quot;$masterListForStr$slaveListForStr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后生成redis官方的tb脚本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/root/redis-3.2.8/src/redis-trib.rb create --replicas 1 ip:port                 -------这边是先都是主后面都是备，一一对应，这个脚本有自己均衡m/s的功能，不一定会按着对应分配master和slave，但是正常情况下都是对应的。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由此可见shell的自动化脚本确实很强大，可以解决很多问题。&lt;/p&gt;

&lt;h2 id=&#34;test结构&#34;&gt;test结构&lt;/h2&gt;

&lt;p&gt;if test condition-true 这种形式和 if[condition-true]这种形式是等价的&lt;/p&gt;

&lt;p&gt;有一个专用命令&amp;rdquo;[&amp;ldquo;(左中括号,特殊字符).这个命令与 test 命令等价。在版本 2.02 的 Bash 中,推出了一个新的[[&amp;hellip;]]扩展 test 命令.因为这种表现形式可能对某些语 言的程序员来说更加熟悉.注意&amp;rdquo;[[&amp;ldquo;是一个关键字,并不是一个命令.&lt;/p&gt;

&lt;p&gt;Bash 把[[ $a -lt $b ]]看作一个单独的元素,并且返回一个退出码.&lt;/p&gt;

&lt;p&gt;[-f filename]相当于判断文件是否存在&lt;/p&gt;

&lt;p&gt;[-d dir]        判断目录是否存在&lt;/p&gt;

&lt;p&gt;[ -n string ]  –n 字符串 字符串的长度非零&lt;/p&gt;

&lt;p&gt;[ -z string ]  字符串的长度零&lt;/p&gt;

&lt;p&gt;[ -a FILE ] 如果 FILE 存在则为真。&lt;/p&gt;

&lt;p&gt;[ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。&lt;/p&gt;

&lt;p&gt;[ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。&lt;/p&gt;

&lt;p&gt;[ -d FILE ] 如果 FILE 存在且是一个目录则为真。&lt;/p&gt;

&lt;p&gt;[ -e FILE ] 如果 FILE 存在则为真。&lt;/p&gt;

&lt;p&gt;[ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。&lt;/p&gt;

&lt;p&gt;[ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。&lt;/p&gt;

&lt;p&gt;[ -h FILE ] 如果 FILE 存在且是一个符号连接则为真。&lt;/p&gt;

&lt;p&gt;[ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。&lt;/p&gt;

&lt;p&gt;[ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。&lt;/p&gt;

&lt;p&gt;[ -r FILE ] 如果 FILE 存在且是可读的则为真。&lt;/p&gt;

&lt;p&gt;[ -s FILE ] 如果 FILE 存在且大小不为0则为真。&lt;/p&gt;

&lt;p&gt;[ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。&lt;/p&gt;

&lt;p&gt;[ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。&lt;/p&gt;

&lt;p&gt;[ -w FILE ] 如果 FILE 如果 FILE 存在且是可写的则为真。&lt;/p&gt;

&lt;p&gt;[ -x FILE ] 如果 FILE 存在且是可执行的则为真。&lt;/p&gt;

&lt;p&gt;[ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。&lt;/p&gt;

&lt;p&gt;[ -G FILE ] 如果 FILE 存在且属有效用户组则为真。&lt;/p&gt;

&lt;p&gt;[ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。&lt;/p&gt;

&lt;p&gt;[ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。&lt;/p&gt;

&lt;p&gt;[ -S FILE ] 如果 FILE 存在且是一个套接字则为真。&lt;/p&gt;

&lt;h3 id=&#34;shell内建变量&#34;&gt;shell内建变量&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$BASH
这个变量将指向 Bash 的二进制执行文件的位置.

$BASH_ENV
这个环境变量将指向一个 Bash 启动文件,这个启动文件将在调用一个脚本时被读取.

$BASH_SUBSHELL
这个变量将提醒 subshell 的层次,这是一个在 version3 才被添加到 Bash 中的新特性.

$BASH_VERSINFO[n]
记录 Bash 安装信息的一个 6 元素的数组.与下边的$BASH_VERSION 很像

$DIRSTACK
在目录栈中最上边的值

$EDITOR
脚本调用的默认编辑器,一般是 vi 或者是 emacs.

$EUID
&amp;quot;effective&amp;quot;用户 ID 号.

$FUNCNAME 当前函数的名字.

$GLOBIGNORE
一个文件名的模式匹配列表

$GROUPS
当前用户属于的组.

$HOME
用户的 home 目录

$HOSTNAME
hostname 命令将在一个 init 脚本中,在启动的时候分配一个系统名字. gethostname()函数将用来设置这个$HOSTNAME 内部变量

$HOSTTYPE
主机类型

$IFS 内部域分隔符.

$IGNOREEOF
忽略 EOF

$LC_COLLATE
常在.bashrc 或/etc/profile 中设置,这个变量用来在文件名扩展和模式匹配校对顺序. 如果$LC_COLLATE 被错误的设置,那么将会在 filename globbing 中引起错误的结果.

$LC_CTYPE
这个内部变量用来控制 globbing 和模式匹配的字符串解释.

$LINENO
这个变量记录它所在的 shell 脚本中它所在行的行号.这个变量一般用于调试目的.

$MACHTYPE
系统类型

$OLDPWD你所在的之前的目录

$OSTYPE 操作系统类型.

$PATH
指向 Bash 外部命令所在的位置

$PIPESTATUS
数组变量将保存最后一个运行的前台管道的退出码

$PPID
一个进程的$PPID 就是它的父进程的进程

$PROMPT_COMMAND 这个变量保存一个在主提示符($PS1)显示之前需要执行的命令

$PS1  2  3  4 提示符

$PWD 工作目录(你当前所在的目录). 与 pwd 内建命令作用相同.

$SHELLOPTS
这个变量里保存 shell 允许的选项,这个变量是只读

$SHLVL
Shell 层次

$TMOUT
如果$TMOUT 环境变量被设置为一个非零的时间值,那么在过了这个指定的时间之后, shell 提示符将会超时,这会引起一个 logout.

$UID
用户 ID 号.
当前用户的 id 号,在/etc/passwd 中记录.
这个值不会因为用户使用了 su 命令而改变.$UID 是只读变量,不容易在命令行或者是脚 本中被修改,并且和内建的 id 命令很相像.

$SECONDS 这个脚本已经运行的时间(单位为秒).

$RANDOM: 产生随机整数
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;字符串&#34;&gt;字符串&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;${#string}
expr length $string 
expr &amp;quot;$string&amp;quot; : &#39;.*&#39;

1 stringZ=abcABC123ABCabc 
3 echo ${#stringZ}
4 echo `expr length $stringZ`                  -------表达式变量的值，一般用于整数值，也可用于字符串。·
5 echo `expr &amp;quot;$stringZ&amp;quot; : &#39;.*&#39;`

15
15
15

expr match &amp;quot;$string&amp;quot; &#39;$substring&#39; $substring 是一个正则表达式
expr &amp;quot;$string&amp;quot; : &#39;$substring&#39; $substring 是一个正则表达式     
两者相等


 stringZ=abcABC123ABCabc
 2 # |------|
 3
 4 echo `expr match &amp;quot;$stringZ&amp;quot; &#39;abc[A-Z]*.2&#39;`
 5 echo `expr &amp;quot;$stringZ&amp;quot; : &#39;abc[A-Z]*.2&#39;`

 8
 8

expr index $string $substring 匹配到子串的第一个字符的位置.

截取
${string:position}
在 string 中从位置$position 开始提取子串.
如果$string 为&amp;quot;*&amp;quot;或&amp;quot;@&amp;quot;,那么将提取从位置$position 开始的位置参数
${string:position:length}
在 string 中从位置$position 开始提取$length 长度的子串.


反向截取
echo ${stringZ:-4}     
# 以${parameter:-default}方式,默认是提取完整地字符串.
echo ${stringZ:(-4)}
echo ${stringZ: -4}
# 现在,它可以工作了.
# 使用圆括号或者添加一个空格来转义这个位置参数.


abcABC123ABCabc
Cabc
Cabc

expr substr $string $position $length
在 string 中从位置$position 开始提取$length 长度的子串.


子串削除
${string#substring}
从$string 的左边截掉第一个匹配的$substring
${string##substring}
从$string 的左边截掉最后一个个匹配的$substring
${string%substring}
从$string 的右边截掉第一个匹配的$substring
${string%%substring}
从$string 的右边截掉最后一个匹配的$substrin  expr substr $string $position $length
在 string 中从位置$position 开始提取$length 长度的子串.


子串替换
${string/substring/replacement}
使用$replacement 来替换第一个匹配的$substring.
${string//substring/replacement}
使用$replacement 来替换所有匹配的$substring.
${string/#substring/replacement}
如果$substring 匹配$string 的开头部分,那么就用$replacement 来替换$substring.
${string/%substring/replacement}
如果$substring 匹配$string 的结尾部分,那么就用$replacement 来替换$substring.

字符串扩展
${parameter}
与$parameter 相同,就是 parameter 的值.
${parameter-default},${parameter:-default} 如果 parameter 没被 set,那么就使用 default.
${parameter=default},${parameter:=default}
如果 parameter 未设置,那么就设置为 default.
${parameter+alt_value},${parameter:+alt_value}
如果 parameter 被 set 了,那就使用 alt_value,否则就使用 null 字符串.
${parameter?err_msg}, ${parameter:?err_msg}
如果 parameter 被 set,那就是用 set 的值,否则 print err_msg.

变量长度/子串删除 ${#var}
字符串长度($var 的字符数量).对于一个数组,${#array}是数组中第一个元素的长度.
一些例外:
${#*}和${#@}将给出位置参数的个数. 对于数组来说${#array[*]}和${$#array[@]}将给出数组元素的个数.
${var#Pattern}, ${var##Pattern}
从$var 开头删除最近或最远匹配$Pattern 的子串.
${var%Pattern}, ${var%%Pattern}
从$var 结尾删除最近或最远匹配$Pattern 的子串.



变量扩展/子串替换
这些结构都是从 ksh 中吸收来的.
${var:pos}
变量 var 从位置 pos 开始扩展.
${var:pos:len}
从位置 pos 开始,并扩展 len 长度个字符.见 Example A-14(这个例子里有这种操作的一个 创造性用法)
${var/Pattern/Replacement}
使用 Replacement 来替换 var 中的第一个 Pattern 的匹配.
${var//Pattern/Replacement}
全局替换.在 var 中所有的匹配,都会用 Replacement 来替换.
向上边所说,如果 Replacement 被忽略的话,那么所有匹配到的 Pattern 都会被删除.
${var/#Pattern/Replacement}
如果 var 的前缀匹配到了 Pattern,那么就用 Replacement 来替换 Pattern.
${var/%Pattern/Replacement}
如果 var 的后缀匹配到了 Pattern,那么就用 Replacement 来替换 Pattern.

间接引用
a=letter_of_alphabet
letter_of_alphabet=z
echo 
# 直接引用.
echo &amp;quot;a = $a&amp;quot;
# 间接引用.
eval a=\$$a
echo &amp;quot;Now a = $a&amp;quot;


a = letter_of_alphabet
Now a = z
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;内建命名&#34;&gt;内建命名&lt;/h2&gt;

&lt;p&gt;I/O&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo
打印(到 stdout)一个表达式或变量
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;系统增量备份和全量备份&#34;&gt;系统增量备份和全量备份&lt;/h2&gt;

&lt;p&gt;全量备份&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -g /tmp/snop -zcvf /tmp/sh.tar.gz /data/sh ------ -g /tmp/snop就是建立了一个快照，便于下面增量备份坐参考，重新全量备份，只要把这个快照删除就行了
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;增量备份&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -g /tmp/snop -zxcf /tmp/sh_add.tar.gz /data/sh --------这边的快照名要和上面全量的一样，但是tar包名不能一样。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以用corntab来每天跑这个脚本，在这个脚本历可以设置每周日进行全量备份，其他时间进行增量备份&lt;/p&gt;

&lt;h2 id=&#34;tmp-snop就是建立了一个快照-便于下面增量备份坐参考-重新全量备份-只要把这个快照删除就行了&#34;&gt;/tmp/snop就是建立了一个快照，便于下面增量备份坐参考，重新全量备份，只要把这个快照删除就行了&lt;/h2&gt;

&lt;p&gt;增量备份&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -g /tmp/snop -zxcf /tmp/sh_add.tar.gz /data/sh --------这边的快照名要和上面全量的一样，但是tar包名不能一样。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以用corntab来每天跑这个脚本，在这个脚本历可以设置每周日进行全量备份，其他时间进行增量备份&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>linux操作命令</title>
      <link>http://kingjcy.github.io/blog/2015/02/23/linux%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Mon, 23 Feb 2015 11:20:38 +0800</pubDate>
      
      <guid>http://kingjcy.github.io/blog/2015/02/23/linux%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/</guid>
      <description>&lt;p&gt;一些linux常用的的操作命令，记录备忘也便于使用时查看。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;tar&#34;&gt;tar&lt;/h3&gt;

&lt;p&gt;-c: 建立压缩档案
-x：解压
-t：查看内容
-r：向压缩归档文件末尾追加文件
-u：更新原压缩包中的文件&lt;/p&gt;

&lt;p&gt;这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。&lt;/p&gt;

&lt;p&gt;-z：有gzip属性的
-j：有bz2属性的
-Z：有compress属性的
-v：显示所有过程
-O：将文件解开到标准输出&lt;/p&gt;

&lt;p&gt;下面的参数-f是必须的&lt;/p&gt;

&lt;p&gt;-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。&lt;/p&gt;

&lt;p&gt;tar -cf all.tar *.jpg
这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。&lt;/p&gt;

&lt;p&gt;tar -rf all.tar *.gif
这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。&lt;/p&gt;

&lt;p&gt;tar -uf all.tar logo.gif
这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。&lt;/p&gt;

&lt;p&gt;tar -tf all.tar
这条命令是列出all.tar包中所有文件，-t是列出文件的意思&lt;/p&gt;

&lt;p&gt;tar -xf all.tar
这条命令是解出all.tar包中所有文件，-t是解开的意思&lt;/p&gt;

&lt;p&gt;压缩&lt;/p&gt;

&lt;p&gt;tar -cvf jpg.tar *.jpg //将目录里所有jpg文件打包成tar.jpg&lt;/p&gt;

&lt;p&gt;tar -czf jpg.tar.gz *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz&lt;/p&gt;

&lt;p&gt;tar -cjf jpg.tar.bz2 *.jpg //将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2&lt;/p&gt;

&lt;p&gt;tar -cZf jpg.tar.Z *.jpg   //将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z&lt;/p&gt;

&lt;p&gt;rar a jpg.rar *.jpg //rar格式的压缩，需要先下载rar for linux&lt;/p&gt;

&lt;p&gt;zip jpg.zip *.jpg //zip格式的压缩，需要先下载zip for linux&lt;/p&gt;

&lt;p&gt;解压&lt;/p&gt;

&lt;p&gt;tar -xvf file.tar //解压 tar包&lt;/p&gt;

&lt;p&gt;tar -xzvf file.tar.gz //解压tar.gz&lt;/p&gt;

&lt;p&gt;tar -xjvf file.tar.bz2   //解压 tar.bz2&lt;/p&gt;

&lt;p&gt;tar -xZvf file.tar.Z   //解压tar.Z&lt;/p&gt;

&lt;p&gt;unrar e file.rar //解压rar&lt;/p&gt;

&lt;p&gt;unzip file.zip //解压zip&lt;/p&gt;

&lt;p&gt;总结&lt;/p&gt;

&lt;p&gt;1、*.tar 用 tar -xvf 解压&lt;/p&gt;

&lt;p&gt;2、*.gz 用 gzip -d或者gunzip 解压&lt;/p&gt;

&lt;p&gt;3、&lt;em&gt;.tar.gz和&lt;/em&gt;.tgz 用 tar -xzf 解压&lt;/p&gt;

&lt;p&gt;4、*.bz2 用 bzip2 -d或者用bunzip2 解压&lt;/p&gt;

&lt;p&gt;5、*.tar.bz2用tar -xjf 解压&lt;/p&gt;

&lt;p&gt;6、*.Z 用 uncompress 解压&lt;/p&gt;

&lt;p&gt;7、*.tar.Z 用tar -xZf 解压&lt;/p&gt;

&lt;p&gt;8、*.rar 用 unrar e解压&lt;/p&gt;

&lt;p&gt;9、*.zip 用 unzip 解压&lt;/p&gt;

&lt;h3 id=&#34;grep&#34;&gt;grep&lt;/h3&gt;

&lt;p&gt;Grep 命令&lt;/p&gt;

&lt;p&gt;1、 参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-I ：忽略大小写 
-c ：打印匹配的行数 
-l ：从多个文件中查找包含匹配项 
-v ：查找不包含匹配项的行 
-n：打印包含匹配项的行和行标,cat也有这个作用 
-E:相当于egrep，深度匹配，多重匹配，比如egrep &amp;quot;a|b&amp;quot; filenamea|b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2、RE（正则表达式）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\ 忽略正则表达式中特殊字符的原有含义 
^ 匹配正则表达式的开始行 
$ 匹配正则表达式的结束行 
\&amp;lt; 从匹配正则表达式的行开始 
\&amp;gt; 到匹配正则表达式的行结束 
[ ] 单个字符；如[A] 即A符合要求 
[ - ] 范围 ；如[A-Z]即A，B，C一直到Z都符合要求 
. 所有的单个字符 
* 所有字符，长度可以为0 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;usermod&#34;&gt;usermod&lt;/h3&gt;

&lt;p&gt;usermod -d /disk01/svn/jiangchunyin jiangchunyin  改变家目录&lt;/p&gt;

&lt;h3 id=&#34;du&#34;&gt;du&lt;/h3&gt;

&lt;p&gt;du -ks * |sort -n    按大小排序&lt;/p&gt;

&lt;h3 id=&#34;echo&#34;&gt;echo&lt;/h3&gt;

&lt;p&gt;echo $?     打印终止状态（进程）&lt;/p&gt;

&lt;h3 id=&#34;find-grep&#34;&gt;find&amp;amp;grep&lt;/h3&gt;

&lt;p&gt;查找当前目录下所有cpp文件中含有getUserProduct的地方&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;find ./ -name &amp;quot;*.cpp&amp;quot; -print | xargs grep getUserProduct    -----xargs也是一种承接，一般不用于cp，mv，和-exec差不多
grep -n &amp;quot;sCrmOrgId&amp;quot; $(find . -name &amp;quot;*.cpp&amp;quot;)

find . -maxdepth 1 -type f -name &amp;quot;&amp;quot; -mtime -1 -exec rm -rf {} \      ----maxdepth 1 目录深度，这个就是一级，-type f表示只是找文件，-mtime -1当前一天的文件，表示多长时间的文件，-表示多少天以内的，+表示多少天以前的，比如三十天以前的-mtime +30 。-exec rm -rf {} \ 执行命令，{}表示前面的结果，最后又一个\是格式
find . -maxdepth 1 -type f -name &amp;quot;&amp;quot; -mtime +30 -exec cp  {} /tmp \      

find . -size +50M 大于五十M的
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sudo&#34;&gt;sudo&lt;/h3&gt;

&lt;p&gt;编辑/etc/sudoers文件。也就是输入命令&amp;rdquo;vim /etc/sudoers&amp;rdquo;,进入编辑模式，找到这一 行：&amp;rdquo;root ALL=(ALL) ALL&amp;rdquo;在起下面添加&amp;rdquo;xxx ALL=(ALL) ALL&amp;rdquo;(这里的xxx是你的用户名)，然后保存退出。可以让普通 用户执行以下只有root用户执行的操作。避免总是用su - 用户切换&lt;/p&gt;

&lt;h3 id=&#34;目录&#34;&gt;目录&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;linux根目录下各文件夹的作用

 /bin 二进制可执行命令   
 /dev 设备特殊文件   
 /etc 系统管理和配置文件   
 /etc/rc.d 启动的配置文件和脚本   
 /home 用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示   
 /lib 标准程序设计库，又叫动态链接共享库，作用类似windows里的.dll文件   
 /sbin 系统管理命令，这里存放的是系统管理员使用的管理程序   
 /tmp 公用的临时文件存储点   
 /root 系统管理员的主目录（呵呵，特权阶级）   
 /mnt 系统提供这个目录是让用户临时挂载其他的文件系统。   
 /lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里   
 /proc 虚拟的目录，是系统内存的映射。可直接访问这个目录来获取系统信息。   
 /var 某些大文件的溢出区，比方说各种服务的日志文件   
 /usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录。其中包含：    
 /usr/x11r6 存放x window的目录   
 /usr/bin 众多的应用程序   
 /usr/sbin 超级用户的一些管理程序   
 /usr/doc linux文档   
 /usr/include linux下开发和编译应用程序所需要的头文件   
 /usr/lib 常用的动态链接库和软件包的配置文件   
 /usr/man 帮助文档   
 /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里   
 /usr/local/bin 本地增加的命令   
 /usr/local/lib 本地增加的库根文件系统
 : /opt 主机额外安装软件所摆放的目录。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scp&#34;&gt;scp&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;scp （-r（目录））文件 用户名@主机名：目录
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;whereis-which&#34;&gt;whereis&amp;amp;which&lt;/h3&gt;

&lt;p&gt;whereis  软件名   &amp;ndash;&amp;gt;查看软件安装路径&lt;/p&gt;

&lt;p&gt;which  软件名     &amp;ndash;&amp;gt;软件软件的运行路径&lt;/p&gt;

&lt;h3 id=&#34;netstat&#34;&gt;netstat&lt;/h3&gt;

&lt;p&gt;netstat -an | grep XXXX&lt;/p&gt;

&lt;p&gt;netstat -tln 查看端口使用情况，而netstat -tln | grep 8083 则是只查看端口8083的使用情况&lt;/p&gt;

&lt;h3 id=&#34;lsof&#34;&gt;lsof&lt;/h3&gt;

&lt;p&gt;lsof -i :8083  查看端口属于哪个程序？端口被哪个进程占用&lt;/p&gt;

&lt;h3 id=&#34;telnet-ping&#34;&gt;telnet&amp;amp;ping&lt;/h3&gt;

&lt;p&gt;ping  网络层协议，是发送一个包给目标主机，目标主机接收到包再返回一个响应的包，测试网络是否通&lt;/p&gt;

&lt;p&gt;telnet  ，ftp都是应用层的类似tcp的协议，但是都是明文密码登陆远程主机，而ssh也是，但是它比较安全，是密文发送的。&lt;/p&gt;

&lt;h3 id=&#34;useradd-passwd&#34;&gt;useradd&amp;amp;passwd&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;useradd –d /usr/sam -m sam&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;此命令创建了一个用户sam，其中-d和-m选项用来为登录名sam产生一个主目录/usr/sam（/usr为默认的用户主目录所在的父目录）。&lt;/p&gt;

&lt;p&gt;假设当前用户是sam，则下面的命令修改该用户自己的口令：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;passwd&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Old password:******&lt;/p&gt;

&lt;p&gt;New password:*******&lt;/p&gt;

&lt;p&gt;Re-enter new password:*******&lt;/p&gt;

&lt;p&gt;如果是超级用户，可以用下列形式指定任何用户的口令：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;passwd sam&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;New password:*******&lt;/p&gt;

&lt;p&gt;Re-enter new password:*******&lt;/p&gt;

&lt;h3 id=&#34;cat&#34;&gt;cat&lt;/h3&gt;

&lt;p&gt;不看注释
cat filename | grep -v &amp;ldquo;^#&amp;rdquo;&lt;/p&gt;

&lt;h3 id=&#34;ifconfig&#34;&gt;ifconfig&lt;/h3&gt;

&lt;p&gt;显示本机的ip，这只是一个工具，可以去看对应的网卡配置文件/etc/sysconfig/network-scripts/&lt;/p&gt;

&lt;h3 id=&#34;命令行和界面模式&#34;&gt;命令行和界面模式&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;vi /etc/inittab
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于centos6和7都是这个文件，但是表现方式不一样，重点都是run level是3则是命令行模式运行。5则是界面模式运行，前提是你安装了图型界面。&lt;/p&gt;

&lt;h3 id=&#34;网络设置&#34;&gt;网络设置&lt;/h3&gt;

&lt;p&gt;centos 7在/etc/sysconfig/metwork-script/下面的的ifcfg-不是lo的文件，设置其静态ip&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BOOTPROTO=&amp;quot;static&amp;quot;
IPADDR=192.168.56.102 #静态IP  
GATEWAY=192.168.0.1 #默认网关  
NETMASK=255.255.255.0 #子网掩码  
DNS1=114.114.114.114 #DNS 配置  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后重启network&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl restart network
ifconfig
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就可以看到成功设置ip了，然后最好把开始启动设置ONBOOT=&amp;ldquo;yes&amp;rdquo;&lt;/p&gt;

&lt;h3 id=&#34;tr&#34;&gt;tr&lt;/h3&gt;

&lt;p&gt;tr命令可以对来自标准输入的字符进行替换、压缩和删除。它可以将一组字符变成另一组字符，经常用来编写优美的单行命令，作用很强大。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-c或——complerment：取代所有不属于第一字符集的字符；
-d或——delete：删除所有属于第一字符集的字符；
-s或--squeeze-repeats：把连续重复的字符以单独一个字符表示；
-t或--truncate-set1：先删除第一字符集较第二字符集多出的字符。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实例：&lt;/p&gt;

&lt;p&gt;大小写转化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;HELLO WORLD&amp;quot; | tr &#39;A-Z&#39; &#39;a-z&#39;
hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;删除数字，是可以用范围的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;hello 123 world 456&amp;quot; | tr -d &#39;0-9&#39; 
hello world 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将制表符转换为空格&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat text | tr &#39;\t&#39; &#39; &#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cat-1&#34;&gt;cat&lt;/h3&gt;

&lt;p&gt;cat -A filename      &amp;mdash;-show all,用于查看是否有乱码&lt;/p&gt;

&lt;h3 id=&#34;sort&#34;&gt;sort&lt;/h3&gt;

&lt;p&gt;cat finenema | sort &amp;mdash;-排序&lt;/p&gt;

&lt;h3 id=&#34;find&#34;&gt;find&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;-type：根据不同的文件类型筛选
f普通文件
d目录文件
l符号链接文件
b块设备 文件
c字符设备文件
p管道文件
s套接字文件



处理动作：
　　　　　　　　　　-print：输出至标准输出；默认的动作；
　　　　　　　　　　-ls：类似于对查找到的文件执行“ls -l”命令，输出文件的详细信息；
　　　　　　　　　　-delete：删除查找到的文件；
　　　　　　　　　　-fls /PATH/TO/SOMEFILE：把查找到的所有文件的长格式信息保存至指定文件中；
　　　　　　　　　　-ok COMMAND {} \; ：对查找到的每个文件执行由COMMAND表示的命令；每次操作都由用户进行确认；
　　　　　　　　　　-exec COMMAND {} \; ：对查找到的每个文件执行由COMMAND表示的命令；
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cut&#34;&gt;cut&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。
如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。

主要参数
-b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。
-c ：以字符为单位进行分割。
-d ：自定义分隔符，默认为制表符。
-f  ：与-d一起使用，指定显示哪个区域。
-n ：取消分割多字节字符。仅和 -b 标志一起使用。如果字符的最后一个字节落在由 -b 标志的 List 参数指示的&amp;lt;br /&amp;gt;范围之内，该字符将被写出；否则，该字符将被排除。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;举个例子吧，当你执行ps命令时，会输出类似如下的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[rocrocket@rocrocket programming]$ who
rocrocket :0           2009-01-08 11:07
rocrocket pts/0        2009-01-08 11:23 (:0.0)
rocrocket pts/1        2009-01-08 14:15 (:0.0)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果我们想提取每一行的第3个字节，就这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[rocrocket@rocrocket programming]$ who|cut -b 3
c
c
c
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ssh&#34;&gt;ssh&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;这边主要讲一下免密码登录，好多次都需要查找一番，决定记下来

A机器生成ssh的私钥和公钥

    ssh-keygen -t rsa

就会生成对应的私钥和公钥文件。将公钥文件id_rsa.pub上传到机器B上，注意这边最好不要直接复制容易乱码导致ssh免密码登录失败

    scp id_rsa.pub user@ip:pwd

然后就是将公钥放到B机器上的这个文件中authorized_keys

    cat id_rsa.pub &amp;gt;&amp;gt; authorized_keys
    chmod 600 authorized_keys

这样就可以了，同样使用于mac系统。

这边设计一个非root用户设置免密码登录的权限问题，权限太大也不行，家目录为755，.ssh的权限700， authorized_keys的权限600， 就够了，发现无法免密码登录就去查看日志/var/log/secure就知道了。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dirname和basename&#34;&gt;dirname和basename&lt;/h3&gt;

&lt;p&gt;dirname命令可以取给定路径的目录部分（strip non-directory suffix from file name）。这个命令很少直接在shell命令行中使用，我一般把它用在shell脚本中，用于取得脚本文件所在目录，然后将当前目录切换过去。&lt;/p&gt;

&lt;p&gt;basename命令则用于获取文件名&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@qzt196 ~]# dirname /usr/bin/sort 
/usr/bin
[root@qzt196 ~]# dirname stdio.h 
.

[root@qzt196 ~]# dirname /usr/bin 
/usr
[root@qzt196 ~]# dirname /usr/bin/ 
/usr
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;uid&#34;&gt;UID&lt;/h3&gt;

&lt;p&gt;shell 的 uid/gid 則是根据 /etc/passwd 的第 3 与第 4 两位决定.&lt;/p&gt;

&lt;p&gt;root 0 0&lt;/p&gt;

&lt;h3 id=&#34;sh&#34;&gt;sh&lt;/h3&gt;

&lt;p&gt;sh -n filename.sh    检查脚本是否正确&lt;/p&gt;

&lt;p&gt;sh -x filename.sh    查看脚本执行的步骤&lt;/p&gt;

&lt;h3 id=&#34;ctontab&#34;&gt;ctontab&lt;/h3&gt;

&lt;p&gt;crontab -e    定时一个任务，在这个任务中编辑对应的执行时间&lt;/p&gt;

&lt;p&gt;12 12 12 * * /usr/bin/bash filename.sh &amp;gt;&amp;gt; /tmp/mysql.log 2&amp;gt;&amp;amp;1&lt;/p&gt;

&lt;p&gt;2&amp;gt;$1  标准输出和标准输入都写到日志中，这边将脚本执行的日志进行重定向到/tmp/mysql.log，同时将标准输出和标准输入都写到这个文件中&lt;/p&gt;

&lt;h3 id=&#34;与&#34;&gt;&amp;amp;&amp;amp;与；&lt;/h3&gt;

&lt;p&gt;命令联合的时候&lt;/p&gt;

&lt;p&gt;&amp;amp;&amp;amp; 前面语句执行成功才能继续执行后面的，否则退出&lt;/p&gt;

&lt;p&gt;；前面的语句成功与否后面都会继续执行&lt;/p&gt;

&lt;h3 id=&#34;sort-1&#34;&gt;sort&lt;/h3&gt;

&lt;p&gt;sort -nr    重大到小排序&lt;/p&gt;

&lt;h3 id=&#34;date&#34;&gt;date&lt;/h3&gt;

&lt;p&gt;date -s 20170413  可以直接这样改变系统时间。&lt;/p&gt;

&lt;h3 id=&#34;hostname&#34;&gt;hostname&lt;/h3&gt;

&lt;p&gt;查看主机名，也可以直接改主机名，hostname name ,等同于修改/proc/sys/kernel/hostname文件。&lt;/p&gt;

&lt;h3 id=&#34;ipcs&#34;&gt;ipcs&lt;/h3&gt;

&lt;p&gt;ipcs用法&lt;/p&gt;

&lt;p&gt;ipcs -a  是默认的输出信息 打印出当前系统中所有的进程间通信方式的信息&lt;/p&gt;

&lt;p&gt;ipcs -m  打印出使用共享内存进行进程间通信的信息&lt;/p&gt;

&lt;p&gt;ipcs -q   打印出使用消息队列进行进程间通信的信息&lt;/p&gt;

&lt;p&gt;ipcs -s  打印出使用信号进行进程间通信的信息&lt;/p&gt;

&lt;p&gt;ipcs -t   输出信息的详细变化时间&lt;/p&gt;

&lt;p&gt;ipcs -p  输出ipc方式的进程ID&lt;/p&gt;

&lt;p&gt;ipcs -c  输出ipc方式的创建者/拥有者&lt;/p&gt;

&lt;p&gt;ipcrm用法
ipcrm -M shmkey  移除用shmkey创建的共享内存段&lt;/p&gt;

&lt;p&gt;ipcrm -m shmid    移除用shmid标识的共享内存段&lt;/p&gt;

&lt;p&gt;ipcrm -Q msgkey  移除用msqkey创建的消息队列&lt;/p&gt;

&lt;p&gt;ipcrm -q msqid  移除用msqid标识的消息队列&lt;/p&gt;

&lt;p&gt;ipcrm -S semkey  移除用semkey创建的信号&lt;/p&gt;

&lt;p&gt;ipcrm -s semid  移除用semid标识的信号&lt;/p&gt;

&lt;h3 id=&#34;netstat-1&#34;&gt;netstat&lt;/h3&gt;

&lt;p&gt;netstat 不加参数持续输出&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-a (all)显示所有选项，默认不显示LISTEN相关
-t (tcp)仅显示tcp相关选项
-u (udp)仅显示udp相关选项
-n 拒绝显示别名，能显示数字的全部转化成数字。加速输出,正常都加上
-l 仅列出有在 Listen (监听) 的服務状态

-p 显示建立相关链接的程序名
-r 显示路由信息，路由表
-e 显示扩展信息，例如uid等
-s 按各个协议进行统计
-c 每隔一个固定时间，执行该netstat命令。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看某个进程暂用的连接&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;netstat -nap | grep pid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看连接某服务端口最多的的IP地址&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; netstat -nat | grep &amp;quot;192.168.1.15:22&amp;quot; |awk &#39;{print $5}&#39;|awk -F: &#39;{print $1}&#39;|sort|uniq -c|sort -nr|head -20
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;top&#34;&gt;top&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;top [-dpqcCSsi] [n]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。&lt;/p&gt;

&lt;p&gt;p 通过指定监控进程ID来仅仅监控某个进程的状态。&lt;/p&gt;

&lt;p&gt;q 该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。&lt;/p&gt;

&lt;p&gt;S 指定累计模式&lt;/p&gt;

&lt;p&gt;s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。&lt;/p&gt;

&lt;p&gt;i 使top不显示任何闲置或者僵死进程。&lt;/p&gt;

&lt;p&gt;c 显示整个命令行而不只是显示命令名&lt;/p&gt;

&lt;p&gt;这些参数也可以在top界面操作。&lt;/p&gt;

&lt;p&gt;常用操作&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;top   //每隔5秒显式所有进程的资源占用情况
top -d 2  //每隔2秒显式所有进程的资源占用情况
top -c  //每隔5秒显式进程的资源占用情况，并显示进程的命令行参数(默认只有进程名)
top -p 12345 -p 6789//每隔5秒显示pid是12345和pid是6789的两个进程的资源占用情况
top -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sysctl&#34;&gt;sysctl&lt;/h3&gt;

&lt;p&gt;linux内核通过/proc虚拟文件系统向用户导出内核信息，用户也可以通过/proc文件系统或通过sysctl命令动态配置内核。比如，如果我们想启动NAT，除了加载模块、配置防火墙外，还需要启动内核转发功能。我们有三种方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;直接写/proc文件系统&lt;/p&gt;

&lt;p&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;利用sysctl命令&lt;/p&gt;

&lt;p&gt;sysctl -w net.ipv4.ip_forward=1&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;sysctl -a可以查看内核所有导出的变量&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;编辑/etc/sysctl.conf&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;添加如下一行，这样系统每次启动后，该变量的值就是1&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net.ipv4.ip_forward = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sysctl参数&lt;/p&gt;

&lt;p&gt;-w   临时改变某个指定参数的值，如         sysctl -w net.ipv4.ip_forward=1&lt;/p&gt;

&lt;p&gt;-a   显示所有的系统参数&lt;/p&gt;

&lt;p&gt;-p   从指定的文件加载系统参数&lt;/p&gt;

&lt;p&gt;关于/etc/sysctl.conf的详解&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;解释一下sysctl.conf文件中参数的意义：

file-max：这个参数表示进程可以同时打开的最大句柄数，这个参数直接限制最大并发连接数。
tcp_tw_reuse：这个参数设置为1,表示允许将TIME-WAIT状态的socket重新用于新的TCP链接。这个对服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。
tcp_keepalive_time：这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是7200 seconds，意思是如果某个TCP连接在idle 2小时后，内核才发起probe。若将其设置得小一点，可以更快地清理无效的连接。
tcp_fin_timeout：这个参数表示当服务器主动关闭连接时，socket保持在FIN-WAIT-2状态的最大时间。
tcp_max_tw_buckets：这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认是i180000,过多TIME_WAIT套接字会使Web服务器变慢。
tcp_max_syn_backlog：这个参数表示TCP三次握手建立阶段接受WYN请求队列的最大长度，默认1024,将其设置大一些可以使出现Nginx繁忙来不及accept新连接的情况时，Linux不至于丢失客户端发起的连接请求。
ip_local_port_range：这个参数定义了在UDP和TCP连接中本地端口的取值范围。
net.ipv4.tcp_rmem：这个参数定义了TCP接受缓存（用于TCP接收滑动窗口）的最小值，默认值，最大值。
net.ipv4.tcp_wmem：这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值，默认值，最大值。
netdev_max_backlog：当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。这个参数表示该队列的最大值。
rmem_default：这个参数表示内核套接字接收缓存区默认的大小。
wmem_default：这个参数表示内核套接字发送缓存区默认的大小。
rmem_max：这个参数表示内核套接字接收缓存区默认的最大大小。
wmem_max：这个参数表示内核套接字发送缓存区默认的最大大小。


1、减少处于FIN-WAIT-2连接状态的时间，使系统可以处理更多的连接。
net.ipv4.tcp_fin_timeout = 2
如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。
对端可以出错并永远不关闭连接，甚至意外当机，缺省值是60秒。
2.2 内核的通常值是180秒，你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN-WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些。

2、以下两参数可解决生产场景中大量连接的Web（cache）服务器中TIME_WAIT过多问题。
net.ipv4.tcp_tw_reuse = 1
表示开启重用。允许将TIME-WAIT sockets重新用于新的 TCP 连接，默认为 0 表示关闭。

3、打开TIME-WAIT套接字重用及回收功能。
net.ipv4.tcp_tw_recycle = 1
表示开启TCP连接中TIME-WAIT sockets的快速收回功能，默认为 0 ，表示关闭。

4、当keepalive起用的时候，TCP发送keepalive消息的频度，缺省是2小时，改为20分钟。
net.ipv4.tcp_keepalive_time = 600

5、允许系统打开的端口范围
net.ipv4.ip_local_port_range = 4000    65000
表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为4000到65000。

6、提高系统支持的最大SYN半连接数(默认1024)
net.ipv4.tcp_max_syn_backlog = 16384
表示SYN队列的长度，默认为1024，加大队列长度为16384，可以容纳最多等待连接的网络连接数。
[root@centos5 ~]# cat /proc/sys/net/ipv4/tcp_max_syn_backlog 
1024

7、系统同时保持TIME_WAIT套接字的最大数量
net.ipv4.tcp_max_tw_buckets = 360000
表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为 5000。
对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。

8、路由缓存刷新频率，当一个路由失败后多长时间跳到另一个路由，默认是300。
net.ipv4.route.gc_timeout = 100

9、在内核放弃建立连接之前发送SYN包的数量。
net.ipv4.tcp_syn_retries = 1

10、减少系统SYN连接重试次数（默认是5）
net.ipv4.tcp_synack_retries = 1
为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。
也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量。

11、设置系统对最大跟踪的TCP连接数的限制(CentOS 5.6无此参数)
net.ipv4.ip_conntrack_max = 25000000
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;lsof-1&#34;&gt;lsof&lt;/h2&gt;

&lt;p&gt;lsof（list open files）是一个列出当前系统打开文件的工具&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;COMMAND：进程的名称
PID：进程标识符
USER：进程所有者
FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等
TYPE：文件类型，如DIR、REG等
DEVICE：指定磁盘的名称
SIZE：文件的大小
NODE：索引节点（文件在磁盘上的标识）
NAME：打开文件的确切名称
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;常用参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lsof  filename 显示打开指定文件的所有进程
lsof -a 表示两个参数都必须满足时才显示结果
lsof -c string   显示COMMAND列中包含指定字符的进程所有打开的文件
lsof -u username  显示所属user进程打开的文件
lsof -g gid 显示归属gid的进程情况
lsof +d /DIR/ 显示目录下被进程打开的文件
lsof +D /DIR/ 同上，但是会搜索目录下的所有目录，时间相对较长
lsof -d FD 显示指定文件描述符的进程
lsof -n 不将IP转换为hostname，缺省是不加上-n参数
lsof -i 用以显示符合条件的进程情况
lsof -i[46] [protocol][@hostname|hostaddr][:service|port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;比如查看22端口的运行情况&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lsof -i :22
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以用于恢复已经删除的数据，文件被删除，但是正在对其读写的进程还是会继续对其进行操作，保存在/proc下面对应的进程号下面的文件描述符中，我们可以通过这个来恢复删除的文件&lt;/p&gt;

&lt;p&gt;先看有木有进程占用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lsof | grep 文件名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后将这个文件追加到原来的文件中去&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat /proc/进程id/fd/fid &amp;gt;&amp;gt; 原来文件名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以用于查看指定进程的连接情况，先获取进程id&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ps -ef|grep frps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后根据id来查看&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lsof -p 4721 -nP | grep TCP
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;lsof 的 -nP 参数用于将 ip 地址和端口号显示为正常的数值类型，否则可能会用别名表示。就可以看出来多少连接多少监听&lt;/p&gt;

&lt;h2 id=&#34;iptables&#34;&gt;iptables&lt;/h2&gt;

&lt;p&gt;查看当前规则&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -L -n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加指定端口到防火墙&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -I INPUT -p 协议 --dport 端口号 -j ACCEPT
iptables -I INPUT -p udp --dport 161 -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tail和head&#34;&gt;tail和head&lt;/h2&gt;

&lt;p&gt;显示前几行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;head -n number  filename
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显示后几行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tail -n number filename
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tail的-f参数可以不断刷新文件&lt;/p&gt;

&lt;h2 id=&#34;netstat和ifconfig&#34;&gt;netstat和ifconfig&lt;/h2&gt;

&lt;p&gt;安装&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install net-tools 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;dig&#34;&gt;dig&lt;/h2&gt;

&lt;p&gt;dns解析的命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dig google.com
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>